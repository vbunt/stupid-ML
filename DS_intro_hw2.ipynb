{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wj25Xo8RSMgG"
   },
   "source": [
    "## Введение в Машинное Обучение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Urzq8ZMwSOmZ"
   },
   "source": [
    "## Практическое домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFccydP1SPMx"
   },
   "source": [
    "### Общая информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7p2ZSLPSPSl"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Выбран кодовый формат\n",
    "```\n",
    "\n",
    "Дата выдачи: 08.06.2022\n",
    "\n",
    "Дедлайн: 15.06.2022 23:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fh4q9p_SPVI"
   },
   "source": [
    "### О задании\n",
    "\n",
    "Задание состоит из 4 частей. В рамках данной работы вам нужно будет работать с текстовыми объявлениями с платформы Avito. \n",
    "\n",
    "[ссылочка на связанный контест с дз](https://www.kaggle.com/competitions/hse-intro-ds-2022-hw2/overview)\n",
    "\n",
    "Теперь вам придется более плотнее поработать с текстом. А именно: построить некоторые статистики на имеющихся текстовых данных. Заняться лемматизацией/стэммингом, поработать с фильтрацией текстовых данных.\n",
    "\n",
    "Данные для домашнего задания расположены там же в контесте. Он также имеет четкий дедлайн, до которого вы можете заслать туда посылки (дедлайн в нем стоит чуть позже дедлайна дз, на всякий случай).\n",
    "\n",
    "Для доступа к данным и лидерборду в контесте необходимо принять его правила. С ними все просто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i12pGUp1SPXz"
   },
   "source": [
    "### Формат сдачи\n",
    "\n",
    "Оформленный юпитер ноутбук отправляете на почту: `Anshtein99@mail.ru`\n",
    "\n",
    "В теме письма указать (x - номер группы): 2022_fikl_ml_dz2_Surname_Name\n",
    "\n",
    "Файл должен именоваться так: dz2_Surname_Name.ipynb (и да, здесь нужны именно ваши фамилия и имя)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FwsSr9GVdx6"
   },
   "source": [
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBdxqV4-Vd0w"
   },
   "source": [
    "**Дисклеймер!!!!** не удаляйте, пожалуйста, поле id из ваших данных, ни из тестовых, ни из учебных. Иначе вашы шансы сдать свои сабмишшины в систему будут стремиться к 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO0Yuza2VmG0"
   },
   "source": [
    "UPD. В рамках этого задания данные имеют достаточно внушительный объем, поэтому рекомендуем вам выполнять данную работу в юпитер коллабе.\n",
    "\n",
    "Также важно!!!: промежуточные вычисления вы можете сохранять на жесткий диск коллаба, т.к. в какой-то момент все необходимые матрицы могут не влезть к вам в оперативную память.\n",
    "Также стоит сохранять веса некоторых посчитанных моделей (на всякий случай)\n",
    "Как это делать описано [тут](https://scikit-learn.org/stable/model_persistence.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg6tH-yAWYLO"
   },
   "source": [
    "### 0. Закачка данных\n",
    "\n",
    "В рамках этой дз настоятельно рекомендуем загрузить `train.csv` и `test.csv` предварительно на ваш гугл диск. Это достаточно сильно облегчит вам жизнь при подзагрузке данных сюда в коллаб. Сами датасеты вы сможете подтянуть через код ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPS6SQtKEzzE",
    "outputId": "97bd5535-5a44-4739-a948-69858202589c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive') #путь_до_файла_с_обучением_внутри_вашего_гуглодиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzwSNZvcXGDk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Train = pd.read_csv('/content/drive/MyDrive/ds_intro_hw2/train_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTQZngXqXybQ"
   },
   "source": [
    "Как вы можете заметить, наш датасет для обучения весит достаточно много, а в ресурсах на коллабе мы ограничены, поэтому в рамках учебного ресерча мы перейдем к исследованию конкретной части семпла нашего трейна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1NvTG7_XX-E"
   },
   "outputs": [],
   "source": [
    "## ну и зафиксируем рандом на всякий случай)\n",
    "Train = Train.sample(1000000, random_state=1337)\n",
    "## так жизнь пойдет легче"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MdK_UHiZxDN"
   },
   "source": [
    "### 1. Копаемся в полученных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0JXUoeuaWe_"
   },
   "source": [
    "Посмотрим на несколько строк нашего датасета. Первое, что стоит поисследовать, это наши метки, которые удобным образом представлены в текстовом формате. Поэтому...\n",
    "\n",
    "**Заадние 1.** (1 балл). Постройте график распределения имеющихся классов. Хотелось бы увидть какую-нибудь гистограмму, где визуально видно топ-5 самых популярных и топ-5 самых непопулярных классов. Что это за категории?\n",
    "Выведите из нашего трейна по паре объявлений из этих категорий. Можно ли заметить между ними (объявлениями 1 класса) какое-то сходство уже на данном этапе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4ufe62RXX73"
   },
   "outputs": [],
   "source": [
    "# Your code here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apmYAgP8b8IP"
   },
   "source": [
    "**Задание 2.** (1 балл). Попробуем также исследовать некоторое текстовое наполнение наших объявлений. Посчитайте топ-10 самых часто встречаемых слов в объявлениях (т.е. во всем 1млн строк) вне зависимости от их формы. Также рассмотрите топ-10 самых редких слов.\n",
    "\n",
    "На данном этапе, до обработки текста, можно условиться, что за слово в объявлении мы будет считать набор символов, отделенный от других наборов символов двумя пробелами. Сделайте некоторые выводы по полученному топу и антитопу слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdKiwSmiZlpo"
   },
   "outputs": [],
   "source": [
    "# Your code here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-36HSBAqf6f6"
   },
   "outputs": [],
   "source": [
    "Train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5sF9u9rf7Dj"
   },
   "source": [
    "Видно, что есть объекты с пропуском в текстовом поле `description`. Заменим пропуски на пустую строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHvLNyLlf9XK"
   },
   "outputs": [],
   "source": [
    "Train.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrYtg4FRgDGG"
   },
   "source": [
    "Для простоты конкатенируем строки из полей `title` и `description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCGX_2JVf9ts"
   },
   "outputs": [],
   "source": [
    "Train['title&description'] = Train['title'].str[:] + ' ' + Train['description'].str[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqZ60pVbgN4f"
   },
   "source": [
    "Разделим выборку ```Train``` на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUSnCoTqgNmZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Train[['title&description']], Train['Category'], random_state=1337, test_size=100000)\n",
    "\n",
    "del Train ## дальше в качестве данных для обучения используем X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMatYR6wZmGE"
   },
   "source": [
    "### 2. Обработка текста\n",
    "\n",
    "Как вы могли заметить в рамках предыдущих пунктов, наши объявления несут в себе некоторый текстовый \"мусор\". Различные местоимения, междометия, или вообще набор \"\\n\" и \"\\t\". Так что звучит довольно логично следующая мысль: давайте мы избавимся от этого мусора в тексте и проведем некоторую фильтрацию данных.\n",
    "\n",
    "Также в купе с этим на ум приходит информация о том, что в наших объявлениях одни и те же слова могут быть записаны в различной языковой форме, использовать различные падежи. Поэтому что?\n",
    "Да, лемматезация. Благо, мы живем с вами в современном мире, и люди для этой задачи написали уже несколько фреймворков, которые нам с вами смогут помочь в этой задаче, в этой дз я рекомендую использовать pymorphy2.\n",
    "\n",
    "Следующая мысль, которая может прийти на ум в рамках обработки текстовых данных - это стоп слова. Их в наших объявлениях достаточно много (ведь их писали люди). Поэтому их также стоит отфильтровать.\n",
    "\n",
    "**Задание 3.** (2 балла). Реализуйте функцию, которая принимает на вход строку, набор стоп слов и морфо-анализатор, и на выходе выдает набор слов (лемм), отчищенных от пунктуационных, разделяющих символов и стоп слов.\n",
    "\n",
    "Некоторый её возможный шаблон представлен ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWYw4tKwjKkb"
   },
   "source": [
    "Подробнее про использование pymorphy смотрите [тут](https://pymorphy2.readthedocs.io/en/0.6/user/guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m59j7RTnjJQm"
   },
   "outputs": [],
   "source": [
    "## блок с подтягиванием библиотеки для лемматизации\n",
    "!pip install pymorphy2\n",
    "!pip install pymorphy2-dicts\n",
    "!pip install 'DAWG-Python >= 0.7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gyv0jLYsZli5"
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "## словарь, он же файл, который мы выдали вам вместе с домашкой, вы также можете загрузить на диск, чтобы подгрузить его в коллаб\n",
    "stop_words = # Your code here (⊃｡•́‿•̀｡)⊃ пол чтению файла stop_word_ru и получения листа из нужных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElMYlku8Zlf8"
   },
   "outputs": [],
   "source": [
    "def clear_and_morhp(text, stop_words, morph):\n",
    "  '''\n",
    "  text: string - строка с нашим текстом\n",
    "  stop_words - List с выданными вам стоп словами\n",
    "  morph - анализатор текста\\слов для получения лемм\n",
    "  так же не забудьте привести все слова к единому регистру\n",
    "  return List слов, преобразованных до лемм + убраны различные знаки + стоп слова\n",
    "  '''\n",
    "\n",
    "  return []\n",
    "\n",
    "  ## её использование к нашим данн в таком формате: X_train[['title&description']].apply(lambda x: clear_and_morhp(x, stop_words, morph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk6RtT3pj6Dx"
   },
   "source": [
    "Если с реализацией данной функции возникнут проблемы - не стеняйтесь писать об этом в наш чат для получения помощи.\n",
    "\n",
    "Также вы можете реализовать не все 3 составляющих очистки текста, а какую-то их часть, но это даст вам меньше баллов.\n",
    "\n",
    "\n",
    "После реализации данной функции мы можем применить её к нашим данным и получить более \"чистый\" набор слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxZL57hmtSSD"
   },
   "outputs": [],
   "source": [
    "# Your code here (⊃｡•́‿•̀｡)⊃ для получения очищенных данных через вашу функцию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUAEte8lkYR4"
   },
   "source": [
    "### 3. Построение простых эмбеддингов и работа с моделями\n",
    "\n",
    "Сейчас вы визуально можете сравнить по определенному набору строк (допустим вызвав `.head(15)`) как изменились наши текстовые данные после предобработки. Так что мы можем с уверенностью сказать, что некоторое визуальное преобразование появилось. Но а выиграли ли мы с точки зрения достижения результата в рамках нашей задачи. Разберемся в этой части домашки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6npoO_ls5eL"
   },
   "source": [
    "**Задание 3.1** (0.5 балла) В рамках этого пункта нам стоит получить некоторый `бейзлайн`, с которым мы будем сравнивать остальные наши модели. Для этого вернемся к трейну X_train, в котором все еще находился мусор, слова всех форм и стоп-слова. Воспользуемся построением Tf-Idf матрицы от этих данных и также используем SGDClassifier в качестве достаточно простой модели.\n",
    "\n",
    "Ну и в качестве метрики мы будем использовать accuracy (для подсчета этой метрики используем имеющийся у нас уже X_test), т.к. у нас все же многоклассовая классификация. Результат этой модели мы будем сравнивать с другими по ходу этого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vm2GFUI3iELP"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Your code here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFkiHFNptsOy"
   },
   "source": [
    "**Задание 3.2** (0.5 балла) У метода TfidfVectorizer есть набор своих параметров. В рамках этого задания мы предлагаем вам поизучать возможные гиперпараметры этого метода и подобрать такие значения, которые вам позволят получить более лучший результат на непредобработанном X_train на той же простой модели SGDClassifier. Как вариант вы можете рассмореть н-граммы большей длины или поставить ограничение сверху на кол-во получаемых токенов в данном методе. 3-4 экспериментов с различными значениями гиперпараметорв будет достаточно, чтобы можно было сделать возможные выводы о значениях, которые подходят в рамках нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX62vqpGiEJD"
   },
   "outputs": [],
   "source": [
    "# Your lots of code here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5dZYXm-vkFP"
   },
   "source": [
    "**Задание 3.3** (3 балла) Теперь подключим рассмотрению такой подход к агрегации фичей как Bag of words. В каком-то смысле, математически он слабее tf-idf подхода, но для этого мы и столкнем их в рамках нашего задания, чтобы посмотреть на результат.\n",
    "\n",
    "В рамках этой части домашки предобработайте **уже очищенные** данные через tf-idf и bag of words подходы. И на полученных наборах фичей обучите **SGDClassifier**, какой-нибудь градиентный бустинг (к примеру XGBoost) и удобное для вас дерево решений (из того же sklearn). \n",
    "\n",
    "**Минимально** у вас должно получиться **6 экспериментов**, между которыми вы сравниваете полученные accuracy. Также для устойчивого обучения стоит поиграться с параметрами двух выбранных моделей и подходов агрегации, или же провести дополнительные эксперименты, чтобы сделать выводы, как изменение параметров моделей обучения от дефолтных влияет на наши итоговые результаты.\n",
    "\n",
    "После проведенных экспериментов стоит изложить некоторые выводы о полученных результатах. Как повлияли разные подходы tf-id и bag of words на обучение одной и той же модели, как сопоставимы результаты с этими подходами на разных моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec0HMM3-iEGW"
   },
   "outputs": [],
   "source": [
    "# Your 4 experiments here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmwPRMCsvk3X"
   },
   "source": [
    "### 4. В погоне за кагглом (снова)\n",
    "\n",
    "**Задание 4.** (1 балл) Да, вам снова нужно попробовать собрать сабмит для нашей тестирующей системе на каггле, для этого:\n",
    "Вы выбираете одну из рассмотренных пар: подхода к агрегации фичей и саму модель (или же берете вообще какой-нибудь LinearSVC, мы не запрещаем).\n",
    "Делаете такую же предобработку данных к тесту (очистка, агрегация фичей), и по выбранной вами модели строите предикт для тестовых данных. Сохранить его также стоит сразу по пути на диск: `/content/drive/MyDrive/ds_intro_hw2/submit.csv`, чтобы его было оттуда файликом проще забрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpUK0nMPXGA2"
   },
   "outputs": [],
   "source": [
    "Test = pd.read_csv('/content/drive/MyDrive/то_же_самое_с_файлом_для_тестирования.csv')\n",
    "\n",
    "# Your cleaning text and predict here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I6sGmEr2eG8"
   },
   "source": [
    "### 5. Рисерч\n",
    "\n",
    "**Задание 5.** (1 балл) В рамках этого пункта мы предлагаем вам еще поработать над данной задачей в другом подходе. В рамках задания 3 мы обучили некоторый ансамбл моделей. А что, если они будут работать над нашей задачей вместе? Да, фактически в этой задаче может помочь некотрое ансамблирование моделей.\n",
    "\n",
    "Для его более честной и усточивой работы, к имеющимся обучающим данным вы можете применить бустреп к каждой из n-моделей (сколько вы выберете - дело ваше, но желательно не меньше 3), чтобы ей на вход поступили разные подмножества данных.\n",
    "\n",
    "Или же вы можете поискать другие полезные закономерности в имеющихся данных, которые помогут улучшить нашу метрику качества по этой задаче. В этом плане мы вас не ограничиваем.\n",
    "\n",
    "Но если все же в голову ничего не приходит, предлагаем рассмотреть ансамблирование нескольких моделей.\n",
    "\n",
    "В рамках ограничения оперативной памяти, вы можете их обучить по отдельности, после сохранить черзе `pickle` и после подгрузить их для некторого ансамблирования. Итоговый класс вы можете выбирать через выбор большинства, или же предложить свою эвристику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1-pSxc61uTS"
   },
   "outputs": [],
   "source": [
    " # Your research here (⊃｡•́‿•̀｡)⊃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qKqI7n0h6u9"
   },
   "source": [
    "### *Дополнительное задание\n",
    "\n",
    "**Задание 6.** (+1 доп балл) Попробуйте использовать дополнительные подходы генерации признаков на текстовых даннных (fasttext, w2v и др) и для дальнейшего обучения моделей. Повысилось ли качество модели? Сделайте выводы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxQe1qSkioJH"
   },
   "outputs": [],
   "source": [
    " # Your research here (⊃｡•́‿•̀｡)⊃"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_intro_hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
